# AI Web Testing Agent - Documentation

## Table of Contents

1.  [Overall Architecture and Flow](#overall-architecture-and-flow)
    *   [Recorder Mode Flow](#recorder-mode-flow)
    *   [Executor Mode Flow (Inferred)](#executor-mode-flow-inferred)
2.  [Core Components](#core-components)
    *   [main.py (Entry Point)](#mainpy-entry-point)
    *   [agent.py (WebAgent)](#agentpy-webagent)
    *   [browser_controller.py (BrowserController)](#browser_controllerpy-browsercontroller)
    *   [llm_client.py (LLMClient)](#llm_clientpy-LLMClient)
    *   [task_manager.py (TaskManager)](#task_managerpy-taskmanager)
    *   [vision_processor.py (VisionProcessor)](#vision_processorpy-visionprocessor)
    *   [executor.py (TestExecutor - *Inferred*)](#executorpy-testexecutor---inferred)
    *   [utils.py](#utilspy)
3.  [DOM Subsystem (`dom/`)](#dom-subsystem-dom)
    *   [dom/buildDomTree.js (Browser-side Script)](#dombuilddomtreejs-browser-side-script)
    *   [dom/views.py (Python Data Structures)](#domviewspy-python-data-structures)
    *   [dom/service.py (DomService)](#domservicepy-domservice)
    *   [dom/history/ (DOM History Tracking)](#domhistory-dom-history-tracking)
4.  [Key Data Schemas](#key-data-schemas)
    *   [Recorded Test Steps (JSON Output)](#recorded-test-steps-json-output)
    *   [Agent History Entries](#agent-history-entries)
    *   [Task Manager Subtasks](#task-manager-subtasks)
    *   [DOM Nodes (Python)](#dom-nodes-python)
5.  [Setup and Usage](#setup-and-usage)

---

## 1. Overall Architecture and Flow

This project implements an AI-assisted web testing agent capable of two primary modes: `record` and `execute`. The core idea is to use a Large Language Model (LLM) like Google LLM to help automate the creation and execution of web UI tests.

*   **Record Mode:** An interactive process where the user provides a high-level test case description (feature). The agent, guided by the LLM, breaks this down into planned steps. For each step, the agent interacts with the browser, fetches the current state (DOM structure), asks the LLM to suggest the specific action (e.g., click, type) and target element based on the planned step description and the visible elements. The user is prompted to confirm or override the AI's suggestion (by clicking the correct element). The confirmed/overridden action is executed, and the corresponding step (with a robust selector) is recorded into a JSON file.
*   **Execute Mode:** A non-interactive process that takes a previously recorded JSON test file and executes the steps sequentially using the browser controller. It performs actions and assertions defined in the file and reports a Pass/Fail result. (Note: The `executor.py` code was not provided, so this flow is inferred from `main.py` and typical test execution patterns).

### Recorder Mode Flow

1.  **Initialization (`main.py`):**
    *   Parses command-line arguments (`--mode record`).
    *   Loads the LLM API key (`utils.load_api_key`).
    *   Displays a security warning.
    *   Initializes `LLMClient` and `WebAgent` (in recorder mode, forcing non-headless).
    *   Prompts the user for a natural language feature/test case description.

2.  **Test Planning (`agent.py: _plan_subtasks`):**
    *   The `WebAgent` sends the feature description to the `LLMClient`.
    *   The LLM returns a list of high-level test steps (e.g., "Navigate to...", "Click login button", "Verify welcome message").
    *   The `WebAgent` populates the `TaskManager` with these planned steps.

3.  **Step-by-Step Recording Loop (`agent.py: record`):**
    *   The `WebAgent` gets the next pending/retryable planned step from the `TaskManager`.
    *   **State Gathering:**
        *   Gets the current URL from `BrowserController`.
        *   Gets the structured DOM (`BrowserController.get_structured_dom`). This involves:
            *   `DomService` executing `buildDomTree.js` in the browser.
            *   `buildDomTree.js` analyzing the live DOM, identifying visible/interactive elements, assigning `highlightIndex`, and returning a map of node data.
            *   `DomService` parsing the JS map into Python `DOMElementNode` objects.
            *   `BrowserController` iterating through the resulting `selector_map` and generating a robust `css_selector` for each interactive node using `DomService._enhanced_css_selector_for_element`. The DOM state (`_latest_dom_state`) now holds nodes with pre-generated selectors.
    *   **Step Type Handling:**
        *   **Navigation/Scroll:** If the planned step is "Navigate to..." or "Scroll...", the `WebAgent` parses the URL/direction and calls `_execute_action_for_recording` directly. The step is recorded.
        *   **Verification:** If the step starts with "Verify...", `_handle_assertion_recording` is called. This prompts the user to confirm/provide a target element selector and choose an assertion type (text contains, visible, attribute equals, etc.). The assertion step is recorded.
        *   **Interactive (Click/Type):** For other steps, assumed to be clicks or types:
            *   **AI Suggestion (`_determine_action_and_selector_for_recording`):** The `WebAgent` sends the planned step description, URL, and the formatted DOM context string (from `DOMElementNode.generate_llm_context_string`, including `[index]` markers) to the `LLMClient`. The LLM is asked to return the `action` (click/type), the `index` of the target element from the context, and any parameters (like text to type). The agent looks up the pre-generated `suggested_selector` using the returned index from the `_latest_dom_state.selector_map`.
            *   **User Interaction (`_handle_interactive_step_recording`):**
                *   The AI's suggested element is highlighted (`BrowserController.highlight_element`).
                *   A click listener is set up (`BrowserController.setup_click_listener`).
                *   The agent waits (`BrowserController.wait_for_user_click_or_timeout`) for either the user to click an element (override) or for a timeout.
                *   If override: The clicked element's selector is captured (via JS), and this `final_selector` is used.
                *   If timeout: The user is prompted via console to Accept (use `suggested_selector`), Skip, or Abort.
                *   The chosen action (`click` or `type`) is executed on the `final_selector` using `_execute_action_for_recording`. Parameterization is offered for typed values.
                *   If execution succeeds, the step (action, description, parameters, `final_selector`, wait) is added to `recorded_steps`.
                *   Handles execution failures (retry suggestion, skip, abort).
    *   **Task Update:** The `TaskManager` status for the planned step is updated (`done`, `skipped`, `failed`).
    *   The loop continues until all planned steps are processed, the user aborts, or max iterations are reached.

4.  **Saving (`agent.py: record`):**
    *   If not aborted and steps were recorded, the `recorded_steps` list, along with metadata, is saved to a timestamped JSON file in the `output/` directory.

5.  **Cleanup (`agent.py: record`):**
    *   The `BrowserController` closes the browser.
    *   The final status (success/fail, message, file path) is returned to `main.py`.

### Executor Mode Flow (Inferred)

1.  **Initialization (`main.py`):**
    *   Parses command-line arguments (`--mode execute --file <path> [--headless-execution]`).
    *   Initializes `TestExecutor` (likely passing headless preference).
2.  **Test Loading (`executor.py: run_test` - inferred):**
    *   The `TestExecutor` reads the specified JSON test file.
    *   It parses the `steps` array.
3.  **Browser Setup (`executor.py: run_test` - inferred):**
    *   The `TestExecutor` likely creates and starts a `BrowserController` instance (respecting headless mode).
4.  **Step Execution Loop (`executor.py: run_test` - inferred):**
    *   The executor iterates through each `step` dictionary in the loaded JSON.
    *   For each step:
        *   It identifies the `action` (navigate, click, type, assertion types).
        *   It retrieves the `selector` and `parameters`.
        *   It calls the corresponding method on the `BrowserController` (e.g., `browser_controller.goto(url)`, `browser_controller.click(selector)`, `browser_controller.type(selector, text)`).
        *   For assertion actions (`assert_text_contains`, `assert_visible`, etc.), it performs the check using `BrowserController` methods (`extract_text`, potentially visibility checks inferred from Playwright locators) and compares against expected values in `parameters`.
        *   Applies `wait_after_secs` if specified.
    *   **Error Handling:** If any action or assertion fails, the executor:
        *   Records the failure details (step ID, description, error message).
        *   Takes a screenshot (`BrowserController.save_screenshot`).
        *   Captures recent console logs (`BrowserController.get_console_messages`).
        *   Stops execution and marks the test as FAILED.
5.  **Reporting (`executor.py: run_test` - inferred):**
    *   If all steps complete successfully, the test is marked as PASSED.
    *   A result dictionary containing status, duration, messages, failure details (if any), screenshots, and console logs is compiled.
6.  **Cleanup (`executor.py: run_test` - inferred):**
    *   The `BrowserController` is closed.
    *   The result dictionary is returned to `main.py`.
7.  **Output (`main.py`):**
    *   Prints a summary of the execution result to the console.
    *   Saves the full result dictionary to a timestamped JSON file in `output/`.

---

## 2. Core Components

### `main.py` (Entry Point)

*   **Purpose:** Orchestrates the overall execution based on command-line arguments. Handles initialization, mode selection, triggering the agent/executor, and displaying final results.
*   **Key Logic:**
    *   Uses `argparse` to handle command-line arguments:
        *   `--mode`: 'record' or 'execute' (required).
        *   `--file`: Path to JSON test file (required for 'execute').
        *   `--headless-execution`: Flag to run executor headlessly.
    *   Loads the `LLM_API_KEY` using `utils.load_api_key`.
    *   Creates the `output/` directory if it doesn't exist.
    *   **Record Mode:**
        *   Displays a security warning.
        *   Initializes `LLMClient`.
        *   Initializes `WebAgent` with `is_recorder_mode=True` and `headless=False`.
        *   Prompts user for the test case description (feature).
        *   Calls `recorder_agent.record(feature_description)`.
        *   Prints the recording result summary.
    *   **Execute Mode:**
        *   Initializes `TestExecutor` with the specified headless preference.
        *   Calls `executor.run_test(args.file)`.
        *   Prints a detailed execution result summary (Pass/Fail, duration, failure details, console logs, screenshot path).
        *   Saves the full execution results dictionary to a JSON file in `output/`.
    *   Includes basic error handling for setup and execution.
*   **Connections:** Instantiates `LLMClient`, `WebAgent`, `TestExecutor`. Uses `utils.load_api_key`. Triggers the main methods (`record` or `run_test`).

### `agent.py` (WebAgent)

*   **Purpose:** The central orchestrator for the AI-assisted recording process. Manages state, interacts with other components (LLM, Browser, Task Manager), handles user interaction, and builds the recorded test steps.
*   **Class: `WebAgent`**
    *   **`__init__(...)`**
        *   Parameters: `llm_client`, `headless` (ignored in recorder mode), `max_iterations`, `max_history_length`, `max_retries_per_subtask`, `max_extracted_data_history`, `is_recorder_mode`.
        *   Logic: Sets the mode flag (`is_recorder_mode`). Forces `headless=False` if recording. Initializes `BrowserController`, `VisionProcessor`, `TaskManager`. Initializes state variables: `history`, `extracted_data_history`, `recorded_steps`, `_current_step_id`, `_user_abort_recording`, `_latest_dom_state`. Logs initialization details.
    *   **`record(feature_description)`**
        *   Purpose: Main entry point for the recording workflow.
        *   Logic:
            *   Checks if in recorder mode.
            *   Initializes recording state (history, steps, etc.).
            *   Starts the `BrowserController`.
            *   Sets the main task in `TaskManager`.
            *   Calls `_plan_subtasks` to get the initial planned steps from the LLM.
            *   Enters the main loop, iterating while steps remain in `TaskManager` and user hasn't aborted:
                *   Gets the next planned task (`TaskManager.get_next_subtask`).
                *   Handles user abort flag.
                *   Gathers current browser state: URL and structured DOM (`BrowserController.get_current_url`, `BrowserController.get_structured_dom`). The DOM state includes pre-generated robust selectors.
                *   Clears browser highlights (`BrowserController.clear_highlights`).
                *   Determines step type based on the planned task description:
                    *   **Navigation:** Parses URL, calls `_execute_action_for_recording('navigate', ...)`, records step, updates `TaskManager`. Handles navigation failure.
                    *   **Verification:** Calls `_handle_assertion_recording` (which manages user interaction, LLM target suggestion, and recording), updates `TaskManager`.
                    *   **Scroll:** Parses direction, calls `_execute_action_for_recording('scroll', ...)`, records step, updates `TaskManager`. Handles scroll failure (non-critical).
                    *   **Interactive (Default):**
                        *   Calls `_determine_action_and_selector_for_recording` to get AI suggestion (action, index, parameters, selector).
                        *   Handles suggestion failure (logs error, updates `TaskManager`, continues to allow retry).
                        *   Handles `action_not_applicable` (logs, skips, updates `TaskManager`).
                        *   If suggestion is 'click' or 'type', calls `_handle_interactive_step_recording` to manage user interaction, execution, and step recording. Updates `TaskManager` internally based on outcome (done, skipped, failed for retry).
                *   Removes click listener (`BrowserController.remove_click_listener`).
                *   Adds a small delay.
            *   Handles loop exit conditions (completed, aborted, max iterations).
            *   If not aborted and steps recorded, formats the data (`test_name`, `feature_description`, `recorded_at`, `steps`) and saves it to a timestamped JSON file in `output/`.
            *   Updates the final recording status dictionary.
        *   Returns: `Dict[str, Any]` containing recording status (success, message, output_file, steps_recorded, duration).
        *   Connections: `TaskManager`, `_plan_subtasks`, `BrowserController`, `_determine_action_and_selector_for_recording`, `_handle_interactive_step_recording`, `_handle_assertion_recording`, `_execute_action_for_recording`.
    *   **`_plan_subtasks(feature_description)`**
        *   Purpose: Uses the LLM to break down the high-level feature description into a sequence of actionable steps.
        *   Logic: Constructs a specific prompt asking the LLM to output a JSON list of single-instruction steps (focused on *intent*, not specific selectors). Calls `LLMClient.generate_text`. Parses the JSON list from the response. Adds the steps to `TaskManager`.
        *   Connections: `LLMClient`, `TaskManager`.
    *   **`_determine_action_and_selector_for_recording(...)`**
        *   Purpose: Uses the LLM to suggest the specific action (`click`/`type`) and target element (`index`) for a given planned step, based on the current DOM context.
        *   Parameters: `current_task` (from TaskManager), `current_url`, `dom_context_str` (formatted HTML with `[index]` markers).
        *   Logic:
            *   Constructs a detailed prompt including the feature, planned step, URL, retry context (if any), the indexed DOM context, and instructions on output format (JSON with `action`, `parameters.index`, `parameters.text`, `reasoning`). Explicitly tells LLM *not* to output selectors.
            *   Calls `LLMClient.generate_text`.
            *   Parses the JSON response (`_clean_llm_response_to_json`).
            *   Validates the suggested action and index.
            *   If action is `click` or `type`: Looks up the target `DOMElementNode` and its pre-generated `suggested_selector` from `self._latest_dom_state.selector_map` using the suggested `index`. Ensures the selector exists (generating it if somehow missed).
            *   Returns a dictionary containing the action, parameters, `suggested_selector`, target `DOMElementNode`, and reasoning, or a failure indication.
        *   Connections: `LLMClient`, `_clean_llm_response_to_json`, uses `_latest_dom_state`.
    *   **`_handle_interactive_step_recording(planned_step, suggestion)`**
        *   Purpose: Manages the user interaction loop for confirming or overriding an AI-suggested `click` or `type` action.
        *   Logic:
            *   Prints the planned step and AI suggestion.
            *   Highlights the suggested element (`BrowserController.highlight_element`).
            *   Sets up the click listener (`BrowserController.setup_click_listener`).
            *   Waits for user click or timeout (`BrowserController.wait_for_user_click_or_timeout`).
            *   **Override Handling:** If a click is detected, retrieves the selector generated by the JS listener. Executes the *original intended action* (from AI suggestion) on the *overridden selector* using `_execute_action_for_recording`. If successful, records the step with the override selector and parameterizes if needed. If override execution fails, prompts user to skip/abort.
            *   **Timeout/No Override:** If no click override, prompts user via console: Accept (Enter/Y), Skip (S), Abort (A).
            *   **Accept Handling:** Executes the action on the *AI's suggested selector* using `_execute_action_for_recording`. If successful, records the step with the suggested selector and parameterizes if needed. If execution fails, prompts user to Retry suggestion (marks task as failed in `TaskManager`), Skip, or Abort.
            *   **Skip/Abort Handling:** Updates `TaskManager` status accordingly. Sets `_user_abort_recording` flag if aborting.
        *   Returns: `True` if the step was handled (recorded, skipped, retry requested), `False` if user aborted.
        *   Connections: `BrowserController` (highlighting, listeners), `_execute_action_for_recording`, `TaskManager`.
    *   **`_handle_assertion_recording(planned_step)`**
        *   Purpose: Guides the user through defining and recording an assertion step based on a "Verify..." planned step.
        *   Logic:
            *   Prints the planned step.
            *   Uses LLM (with a simplified prompt) to suggest a target element index based on the verification description and current DOM context.
            *   Highlights the suggested element (if found).
            *   Prompts the user to confirm the suggested selector or provide a different one.
            *   Prompts the user to choose an assertion type (Text Contains, Is Visible, Attribute Equals, etc.).
            *   Prompts for necessary parameters (expected text, attribute name/value, count).
            *   Records the assertion step with the chosen action, final selector, and parameters in `recorded_steps`.
            *   Updates `TaskManager` status.
        *   Returns: `True` if handled (recorded/skipped), `False` if user aborted.
        *   Connections: `LLMClient`, `BrowserController` (highlighting), `TaskManager`.
    *   **`_execute_action_for_recording(action, selector, parameters)`**
        *   Purpose: Executes a *confirmed* browser action during recording. Does *not* involve AI decision-making at this stage.
        *   Logic: Takes the action type, selector (if applicable), and parameters. Calls the corresponding `BrowserController` method (`goto`, `click`, `type`, `scroll`). Adds implicit `wait_for_load_state` step after navigation. Handles potential `PlaywrightError` or `ValueError` during execution. Saves screenshot on execution failure.
        *   Returns: `Dict` with `success` (bool) and `message` (str).
        *   Connections: `BrowserController`.
    *   **`_add_to_history(entry_type, data)` & `_get_history_summary()`**
        *   Purpose: Manage a list of recent events (actions, results, errors) for potential LLM context.
        *   Logic: Adds timestamped entries, truncates long data, maintains max length. `_get_history_summary` formats it for prompts.
    *   **`_clean_llm_response_to_json(llm_output)`**
        *   Purpose: Extracts and parses JSON content, often wrapped in markdown code blocks, from LLM responses.
        *   Logic: Uses regex to find JSON within ```json ... ``` or finds the outermost `{...}`. Performs pre-processing (escaping quotes within specific string values, handling newlines). Attempts `json.loads`. Validates the result (must be dict with "action" key). Handles `JSONDecodeError`.
    *   **`_get_extracted_data_summary()`**
        *   Purpose: Provides a summary of data extracted in previous steps (potentially useful context, though less critical in recorder mode).
        *   Logic: Formats recent entries from `extracted_data_history`.

### `browser_controller.py` (BrowserController)

*   **Purpose:** Encapsulates all direct interactions with the web browser using the Playwright library. Manages browser lifecycle, navigation, element actions, DOM fetching, highlighting, and recorder-specific JavaScript injection.
*   **Class: `BrowserController`**
    *   **`__init__(headless)`**
        *   Sets headless mode preference. Initializes internal state (playwright, browser, page instances to None). Initializes `console_messages` list.
    *   **`start()`**
        *   Initializes Playwright (`sync_playwright().start()`).
        *   Launches Chromium browser (`playwright.chromium.launch`) with specified headless mode and anti-detection args.
        *   Creates a new browser context (`browser.new_context`) with settings like user agent, viewport, timeout defaults, and injected scripts (`HIDE_WEBDRIVER_SCRIPT`).
        *   Creates a new page (`context.new_page`).
        *   Initializes `DomService` with the created page.
        *   Attaches a listener (`_handle_console_message`) to the page's 'console' events.
    *   **`close()`**
        *   Safely closes the page, context, and browser. Stops Playwright. Clears console messages. Includes error handling.
    *   **Navigation & Page Info:**
        *   **`goto(url)`:** Navigates the page to the URL. Waits for `domcontentloaded`. Adds a small static delay. Handles timeouts and errors.
        *   **`get_html()`:** Returns the full HTML source of the current page.
        *   **`get_current_url()`:** Returns the current page URL.
    *   **Element Interaction:**
        *   **`_find_element(selector, timeout)`:** (Internal helper) Finds the first Playwright `Locator` matching the selector. Waits briefly for 'attached' state and scrolls into view. Returns `Locator` or `None`.
        *   **`click(selector)`:** Finds the element, hovers briefly (optional), then performs `locator.click()` with Playwright's built-in actionability checks and a random delay. Includes robust timeout/error handling and saves a screenshot on failure.
        *   **`type(selector, text)`:** Inputs text. Prioritizes `locator.fill()` (clears first, robust). If `fill` fails, falls back to `locator.clear()` followed by `locator.type()` with character delays. Includes robust timeout/error handling and saves a screenshot on failure.
        *   **`scroll(direction)`:** Scrolls the page 'up' or 'down' using JavaScript `window.scrollBy`. Adds a delay.
    *   **Data Extraction:**
        *   **`extract_text(selector)`:** Finds the element, waits for it to be 'visible', then extracts its text content using `locator.text_content()`. Handles cases where the element exists but isn't visible.
        *   **`extract_attributes(selector, attributes)`:** Finds the element, waits for it to be 'attached', then extracts the specified list of attributes using `locator.get_attribute()`. Returns a dictionary of attribute names to values (or error messages).
    *   **DOM & Structure:**
        *   **`get_structured_dom(...)`:** The primary method for getting the DOM state for the agent.
            *   Calls `self._dom_service.get_clickable_elements()` (which runs the JS).
            *   **Crucially:** Iterates through the `selector_map` in the returned `DOMState` and calls `get_selector_for_node(node)` for each interactive node to ensure the `node.css_selector` attribute is populated with a robust selector *before* returning the `DOMState`.
        *   **`get_selector_for_node(node)`:** Calls the static `DomService._enhanced_css_selector_for_element` to generate the selector for a given `DOMElementNode`.
    *   **Screenshots:**
        *   **`take_screenshot()`:** Takes a screenshot and returns the image data as bytes.
        *   **`save_screenshot(file_path)`:** Takes a screenshot and saves it to the specified file path, creating directories if needed.
    *   **Console Logging:**
        *   **`_handle_console_message(message)`:** Internal callback attached to `page.on('console')`. Appends formatted message details (timestamp, type, text) to `self.console_messages`. Logs messages directly based on type (Error/Warning -> WARNING, others -> DEBUG).
        *   **`get_console_messages()`:** Returns a copy of the captured console messages.
        *   **`clear_console_messages()`:** Clears the internal list of console messages.
    *   **Recorder-Specific JS Interaction:**
        *   **`setup_click_listener()`:** Injects and executes `CLICK_LISTENER_JS` using `page.evaluate()`. This JS adds a global click listener that captures the next click, generates a basic selector for the clicked element, stores it in `window._recorder_override_selector`, and removes itself.
        *   **`remove_click_listener()`:** Injects and executes `REMOVE_CLICK_LISTENER_JS` to remove the listener and clean up the global variable.
        *   **`wait_for_user_click_or_timeout(timeout_seconds)`:** Waits for the `window._recorder_override_selector` variable to be set (indicating a click occurred) using `page.wait_for_function()`. If the condition is met before the timeout, it retrieves and returns the selector stored in the variable. Returns `None` on timeout or error. Ensures the listener is removed afterwards.
        *   **`highlight_element(selector, index, color, text)`:** Injects JS to draw a colored border and an index label overlay over the element matching the selector in the browser window. Creates a container div (`bw-highlight-container`) if it doesn't exist.
        *   **`clear_highlights()`:** Injects JS to remove all highlight overlays and labels by clearing the container div's content.
    *   **Helpers:**
        *   **`_get_random_user_agent()` & `_get_random_viewport()`:** Provide variety for browser context settings.
        *   **`_human_like_delay(min_secs, max_secs)`:** Introduces small random delays after actions.

### `llm_client.py` (LLMClient)

*   **Purpose:** Provides a simple interface to interact with the Google LLM API (specifically `LLM-1.5-flash` for both text and vision) while handling API key configuration and basic rate limiting.
*   **Class: `LLMClient`**
    *   **`__init__(api_key)`**
        *   Configures the `genai` library with the API key.
        *   Initializes the generative models (`LLM-1.5-flash` for text and vision).
        *   Initializes rate limiting state: `MIN_REQUEST_INTERVAL_SECONDS`, `_last_request_time`, and a `threading.Lock` (`_lock`) for thread safety.
    *   **`_wait_for_rate_limit()`**
        *   Internal method called before each API request.
        *   Uses a lock to ensure thread-safe calculation of the required wait time based on `_last_request_time` and `MIN_REQUEST_INTERVAL_SECONDS`.
        *   Sleeps if necessary.
        *   Updates `_last_request_time` *after* the wait.
    *   **`generate_text(prompt)`**
        *   Calls `_wait_for_rate_limit`.
        *   Sends the text prompt to the `text_model`.
        *   Includes improved response handling: checks for `.text`, `.parts`, or `.prompt_feedback.block_reason`.
        *   Logs truncated prompt and response status.
        *   Returns the generated text content or an error message.
    *   **`generate_multimodal(prompt, image_bytes)`**
        *   Calls `_wait_for_rate_limit`.
        *   Opens the image bytes using PIL (`Image.open`).
        *   Sends the prompt and image to the `vision_model`.
        *   Includes similar improved response handling as `generate_text`.
        *   Logs prompt and response status.
        *   Returns the generated text content or an error message.

### `task_manager.py` (TaskManager)

*   **Purpose:** Manages the list of high-level test steps planned by the LLM during the recording process. Tracks the status, attempts, and results for each step.
*   **Class: `TaskManager`**
    *   **`__init__(max_retries_per_subtask)`**
        *   Initializes `main_task` (overall feature description), `subtasks` list, `current_subtask_index`, and `max_retries_per_subtask`.
    *   **`set_main_task(feature_description)`**
        *   Sets the main task description and resets subtasks/index.
    *   **`add_subtasks(test_step_list)`**
        *   Takes a list of step description strings (from `_plan_subtasks`).
        *   Validates the input.
        *   Creates a list of dictionaries, one for each step, initializing `description`, `status` ('pending'), `attempts` (0), `result` (None), `error` (None).
        *   Stores this list in `self.subtasks`. Resets `current_subtask_index`.
    *   **`get_next_subtask()`**
        *   Iterates through `self.subtasks` sequentially.
        *   Finds the first task whose status is 'pending' OR ('failed' AND `attempts` <= `max_retries_per_subtask`).
        *   If found:
            *   Sets `self.current_subtask_index` to the index of this task.
            *   Updates the task's status to 'in_progress'.
            *   Increments the task's `attempts`.
            *   Clears the task's `result`.
            *   Returns the task dictionary.
        *   If no actionable task is found, sets index past the end and returns `None`.
    *   **`update_subtask_status(index, status, result, error, force_update)`**
        *   Updates the specified task's `status`, `result`, and `error` fields. Includes logging. Handles permanent failure logging if max retries are exceeded.
    *   **`get_current_subtask()`**
        *   Returns the subtask dictionary at the `current_subtask_index`, if valid.
    *   **`is_complete()`**
        *   Checks if all subtasks are in a final state ('done', 'skipped', or 'failed' permanently). Returns `True` if complete, `False` otherwise.
    *   **`get_progress_summary()`**
        *   Generates a human-readable string summarizing the status of all tasks (counts of done, skipped, failed, pending) and details about the current or next step.

### `vision_processor.py` (VisionProcessor)

*   **Purpose:** Utilizes the multimodal capabilities of the LLM (LLM Vision) to analyze screenshots, primarily intended to provide visual context or suggest alternative selectors when standard methods fail (though selector generation is now primarily handled differently).
*   **Class: `VisionProcessor`**
    *   **`__init__(llm_client)`**
        *   Stores the `LLMClient` instance.
    *   **`analyze_screenshot_for_action(image_bytes, task_prompt, failed_selector, error_context)`**
        *   Takes screenshot bytes and context about the current task/previous failure.
        *   Constructs a focused prompt asking the vision model to:
            *   Analyze the screenshot relevant to the `task_prompt`.
            *   Identify interactive elements visually.
            *   If `failed_selector` is provided, consider the error and suggest *alternative*, robust CSS selectors based on **native attributes** (ID, name, data-testid, text, etc.), explicitly avoiding AI-generated IDs like `data-ai-id`.
            *   Provide visual descriptions and approximate locations.
        *   Calls `self.llm_client.generate_multimodal` with the prompt and image.
        *   Returns the textual analysis from the LLM.

### `executor.py` (TestExecutor - *Inferred*)

*   **Purpose:** Executes a pre-recorded test script (JSON file) deterministically.
*   **Class: `TestExecutor` (Likely Structure)**
    *   **`__init__(headless)`**
        *   Stores headless preference.
        *   Initializes a `BrowserController` instance.
    *   **`run_test(json_file_path)`**
        *   Loads test steps from the JSON file.
        *   Starts the `BrowserController`.
        *   Iterates through the steps:
            *   Parses `action`, `selector`, `parameters`.
            *   Calls appropriate `BrowserController` methods (goto, click, type, extract_text, etc.).
            *   Performs assertions based on action type (e.g., `assert_text_contains`, `assert_visible`).
            *   Handles failures: logs error, takes screenshot, gets console messages, sets status to FAIL, stops.
            *   Handles waits (`wait_after_secs`).
        *   If all steps pass, sets status to PASS.
        *   Compiles results (status, duration, failure info, logs, screenshot path).
        *   Closes the `BrowserController`.
        *   Returns the results dictionary.
    *   **(Helper methods for assertions)** - May exist internally.

### `utils.py`

*   **Purpose:** Contains common utility functions used across the project.
*   **Functions:**
    *   **`load_api_key()`:**
        *   Loads environment variables from a `.env` file (if present).
        *   Retrieves the `LLM_API_KEY` from environment variables.
        *   Raises a `ValueError` if the key is not found.
        *   Returns the API key string.

---

## 3. DOM Subsystem (`dom/`)

This subsystem is responsible for analyzing the web page's Document Object Model (DOM), identifying interactive elements, generating selectors, and providing a structured representation for the agent and LLM.

### `dom/buildDomTree.js` (Browser-side Script)

*   **Purpose:** This JavaScript code is injected and executed within the context of the web page by the `BrowserController`. Its goal is to traverse the live DOM, identify relevant nodes (especially interactive ones), gather information about them, and return a structured representation back to the Python code.
*   **Execution:** Called by `DomService._build_dom_tree` via `page.evaluate()`.
*   **Key Logic:**
    *   **Initialization:** Takes arguments (`doHighlightElements`, `focusHighlightIndex`, `viewportExpansion`, `debugMode`). Initializes a global `highlightIndex` counter and performance metrics object (`PERF_METRICS`) if `debugMode` is true. Sets up caching (`DOM_CACHE`) for `getBoundingClientRect` and `getComputedStyle`.
    *   **`buildDomTree(node, parentIframe)` (Recursive Function):**
        *   The core recursive function that walks the DOM starting from `document.body`.
        *   **Filtering:** Skips nodes like the highlight container itself, non-element/non-text nodes, script/style tags, and elements clearly outside the viewport (unless `viewportExpansion` is -1 or the element is fixed/sticky).
        *   **Text Nodes:** Processes visible text nodes, storing their content and visibility status.
        *   **Element Nodes:**
            *   Extracts `tagName`, basic `attributes`, and generates an `xpath`.
            *   Checks visibility (`isElementVisible`), position relative to other elements (`isTopElement`), and interactivity (`isInteractiveElement`).
            *   **Interactivity Check (`isInteractiveElement`):** Uses a combination of checks: common interactive tag names (a, button, input, etc.), specific roles, `contenteditable`, event listeners (less reliable), cursor style (`pointer`), and ensures the element isn't explicitly disabled/readonly/inert.
            *   **Highlighting:** If an element is deemed interactive and visible, it's assigned the current `highlightIndex`. If `doHighlightElements` is true, calls `highlightElement` to draw an overlay and label on the page. Increments `highlightIndex`.
            *   **Children Processing:** Recursively calls `buildDomTree` for child nodes. Handles `<iframe>` content and Shadow DOM roots correctly.
    *   **Data Structure:** Builds a map (`DOM_HASH_MAP`) where keys are simple incrementing IDs (as strings) and values are objects containing node data (tagName, attributes, xpath, children IDs, visibility/interactivity flags, highlightIndex).
    *   **Return Value:** Returns an object `{ rootId: string, map: DOM_HASH_MAP, perfMetrics: object | null }`.
*   **Helper Functions:** Contains various helpers like `getXPathTree`, `isTextNodeVisible`, `isElementVisible`, `isInteractiveElement`, `isTopElement`, `isInExpandedViewport`, `highlightElement`, caching helpers (`getCachedBoundingRect`, `getCachedComputedStyle`), etc.

### `dom/views.py` (Python Data Structures)

*   **Purpose:** Defines the Python `dataclass` structures that represent the DOM nodes and overall DOM state, mirroring the data structure returned by `buildDomTree.js`.
*   **Key Classes:**
    *   **`Coordinates`, `CoordinateSet`, `ViewportInfo`:** Dataclasses (using Pydantic if available) to represent geometric information (x, y, width, height, scroll position) associated with elements.
    *   **`DOMBaseNode`:** Base class for DOM nodes, currently holding `parent` and `is_visible`.
    *   **`DOMTextNode(DOMBaseNode)`:** Represents a text node with `text` content.
    *   **`DOMElementNode(DOMBaseNode)`:** Represents an element node. Contains fields like `tag_name`, `xpath`, `attributes`, `children` (list of `DOMElementNode` or `DOMTextNode`), boolean flags (`is_interactive`, `is_top_element`, `is_in_viewport`, `shadow_root`), `highlight_index` (Optional[int]), coordinate objects (`page_coordinates`, `viewport_coordinates`, `viewport_info`), and `css_selector` (Optional[str] - added to store the robust selector).
        *   **`generate_llm_context_string(...)`:** A crucial method that traverses the element tree and produces a formatted string representation suitable for LLM prompts. It indents the structure, includes attributes, and clearly marks interactive elements with their `[highlight_index]`. It distinguishes between interactive and visible static elements, limiting the number of static elements included (`max_static_elements`) to manage context length.
        *   **`get_all_text_till_next_clickable_element(...)`:** Collects text content within an element, stopping descent when another interactive element is found.
        *   **`hash` (cached_property):** Lazily computes a hash for the element using `dom.history.service.HistoryTreeProcessor` for potential state comparison.
    *   **`SelectorMap` (Type Alias):** `Dict[int, DOMElementNode]` - Maps the `highlightIndex` to the corresponding interactive `DOMElementNode`.
    *   **`DOMState`:** A container dataclass holding the root `element_tree` (`DOMElementNode`) and the `selector_map`. This is the primary object returned by `BrowserController.get_structured_dom`.

### `dom/service.py` (DomService)

*   **Purpose:** Acts as the service layer for DOM processing. It loads the JavaScript code, executes it in the browser via Playwright, parses the resulting data structure into the Python `DOMElementNode` objects defined in `dom/views.py`, and provides utilities like robust selector generation.
*   **Class: `DomService`**
    *   **`__init__(page)`**
        *   Takes the Playwright `Page` object.
        *   Loads the `buildDomTree.js` code using `importlib.resources`.
    *   **`get_clickable_elements(...)`**
        *   The main public method to get the DOM state.
        *   Calls the internal `_build_dom_tree` method.
        *   Returns a `DOMState` object containing the parsed tree and selector map.
    *   **`_build_dom_tree(...)`**
        *   Internal method that prepares arguments for the JS script.
        *   Executes the loaded `self.js_code` in the browser page context using `page.evaluate()`.
        *   Handles potential errors during JS execution.
        *   Logs performance metrics from the JS if `debugMode` was enabled.
        *   Calls `_construct_dom_tree` to parse the returned JSON data from the JS.
        *   Returns the root `DOMElementNode` and the `SelectorMap`.
    *   **`_construct_dom_tree(eval_page)`**
        *   Takes the dictionary (`map` and `rootId`) returned by the JS execution.
        *   Iterates through the `map` provided by the JS.
        *   For each node data in the map, calls `_parse_node` to create the corresponding Python `DOMElementNode` or `DOMTextNode`.
        *   Stores parsed nodes in a temporary `node_map` keyed by the JS ID (string).
        *   Populates the `selector_map` by adding any `DOMElementNode` that has a `highlight_index`.
        *   Links parent-child relationships based on the `children` IDs provided in the JS data.
        *   Identifies and returns the root `DOMElementNode` based on `rootId`. Includes error handling for missing root.
        *   Cleans up intermediate maps using `gc.collect()`.
    *   **`_parse_node(node_data)`**
        *   Takes a single node's data dictionary from the JS map.
        *   Determines if it's a Text or Element node.
        *   Creates and returns the appropriate Python object (`DOMTextNode` or `DOMElementNode`), populating its fields from the dictionary. Parses coordinate data into the Pydantic models (`CoordinateSet`, `ViewportInfo`).
        *   Returns the parsed node and a list of its children's IDs (as strings).
    *   **`_enhanced_css_selector_for_element(element)` (Static Method)**
        *   **Purpose:** Generates a robust CSS selector for a given `DOMElementNode`. This is a key part of making the recorded tests less brittle.
        *   **Logic:** Implements a prioritized strategy:
            1.  ID (`#elementId`) - preferred if it looks stable.
            2.  Stable data attributes (`[data-testid='...']`, `[data-cy='...']`, etc.).
            3.  Name attribute (`tagName[name='...']`).
            4.  Aria-label (`tagName[aria-label='...']`).
            5.  Placeholder (for inputs) (`input[placeholder='...']`).
            6.  Specific Role (`tagName[role='button']`).
            7.  Tag + Stable Class Names (filters out dynamic/state classes, e.g., `button.btn.btn-primary`).
            8.  `:nth-of-type(index)` - Added as a fallback *only if* the selector based on tag/class still matches multiple siblings.
            9.  XPath - Used as a last resort if no better CSS selector can be formed.
        *   Includes basic CSS escaping.
        *   **Usage:** This method is called by `BrowserController.get_selector_for_node` *after* the initial DOM tree is built by the JS and parsed by `_construct_dom_tree`.

### `dom/history/` (DOM History Tracking)

*   **Purpose:** This sub-module provides capabilities to compare DOM elements across different points in time, primarily by hashing key structural properties. This is less central to the *recorder* core loop but could be used for verification steps or more advanced analysis.
*   **`dom/history/view.py`**
    *   Defines data structures for historical comparison:
        *   **`HashedDomElement`:** Holds hash values for branch path, attributes, and XPath.
        *   **`DOMHistoryElement`:** A serializable representation of a `DOMElementNode` at a specific time. Includes `tag_name`, `xpath`, `attributes`, `parent_branch_path`, generated `css_selector`, and coordinates. It's designed to be stored or compared later.
*   **`dom/history/service.py`**
    *   **`HistoryTreeProcessor`:** Contains static methods for history operations:
        *   **`convert_dom_element_to_history_element`:** Converts a live `DOMElementNode` into a storable `DOMHistoryElement`, generating the CSS selector using `DomService._enhanced_css_selector_for_element`.
        *   **`find_history_element_in_tree`:** Attempts to find an element in a *new* live DOM tree that matches a given `DOMHistoryElement` by comparing hashes.
        *   **`compare_history_element_and_dom_element`:** Compares a `DOMHistoryElement` and a live `DOMElementNode` using their hashes.
        *   **Hashing Methods (`_hash_dom_history_element`, `_hash_dom_element`, `_parent_branch_path_hash`, `_attributes_hash`, `_xpath_hash`):** Generate consistent hashes based on element properties (tag path, sorted attributes, XPath).

---

## 4. Key Data Schemas

### Recorded Test Steps (JSON Output)

This is the primary output of the `record` mode, saved to a JSON file (e.g., `output/test_*.json`). It represents the sequence of actions and assertions to be performed.

```json
{
  "test_name": "Example_Login_Test",
  "feature_description": "User logs into the example site with valid credentials.",
  "recorded_at": "2023-10-27T10:00:00Z",
  "steps": [
    {
      "step_id": 1, // Sequential identifier
      "action": "navigate", // Type of action (navigate, click, type, scroll, assert_*)
      "description": "Navigate to https://example.com/login", // Original planned step description
      "parameters": { // Action-specific parameters
        "url": "https://example.com/login"
      },
      "selector": null, // CSS selector (null for navigate/global actions)
      "wait_after_secs": 0.5 // Optional small delay after action execution
    },
    {
      "step_id": 2,
      "action": "wait_for_load_state", // Implicit step added after navigation
      "description": "Wait for page navigation to complete",
      "parameters": {
        "state": "domcontentloaded" // e.g., 'load', 'domcontentloaded', 'networkidle'
      },
      "selector": null,
      "wait_after_secs": 0
    },
    {
      "step_id": 3,
      "action": "type",
      "description": "Type username into username field",
      "parameters": {
        "text": "testuser",
        "parameter_name": "login_username" // Optional: for data parameterization
      },
      "selector": "#username_field", // Robust CSS selector determined during recording
      "wait_after_secs": 0.5
    },
    {
      "step_id": 4,
      "action": "click",
      "description": "Click the login button",
      "parameters": {},
      "selector": "button[data-testid='login-button']",
      "wait_after_secs": 1.0 // Longer wait might be needed after login
    },
    {
      "step_id": 5,
      "action": "assert_text_contains", // Assertion action
      "description": "Verify 'Welcome, testuser!' message is present",
      "parameters": {
        "expected_text": "Welcome, testuser!"
      },
      "selector": "div.welcome-message", // Selector for the element to assert against
      "wait_after_secs": 0
    },
    {
        "step_id": 6,
        "action": "assert_visible",
        "description": "Verify logout button is visible",
        "parameters": {},
        "selector": "#logout-btn",
        "wait_after_secs": 0
    }
    // ... more steps
  ]
}
```

### Agent History Entries

Stored in `WebAgent.history`. A list of dictionaries used for LLM context.

```python
# Example Entry
{
    "timestamp": "2023-10-27 10:01:15",
    "type": "LLM Suggestion", # e.g., "Executing Recorder Action", "LLM Parse Error", "Recorder Action Result"
    "data": { # Structure depends on the 'type'
        "action": "click",
        "parameters": {"index": 5},
        "suggested_selector": "#login-button",
        "reasoning": "User planned to click login, element [5] matches."
    } # Data is often truncated for brevity in logs/history
}
```

### Task Manager Subtasks

Stored in `TaskManager.subtasks`. Represents the *planned* steps before they are converted into recorded steps.

```python
# Example Entry
{
    "description": "Click the login button", # From LLM planning
    "status": "done",  # pending, in_progress, done, failed, skipped
    "attempts": 1, # Number of times processing was attempted
    "result": "Recorded AI suggestion as step 4", # Info/result after processing
    "error": None,  # Error message if status is 'failed'
    # Internal fields might exist but aren't primary parts of the schema
}
```

### DOM Nodes (Python)

Defined in `dom/views.py`. These are `dataclass` instances representing the parsed DOM.

*   **`DOMElementNode`:** (Key fields) `tag_name` (str), `xpath` (str), `attributes` (Dict), `children` (List), `is_visible` (bool), `is_interactive` (bool), `highlight_index` (Optional[int]), `css_selector` (Optional[str]), `page_coordinates` (Optional[CoordinateSet]), etc.
*   **`DOMTextNode`:** `text` (str), `is_visible` (bool).
*   **`DOMState`:** `element_tree` (DOMElementNode - root), `selector_map` (Dict[int, DOMElementNode]).

---

## 5. Setup and Usage

1.  **Prerequisites:**
    *   Python 3.x
    *   Install required libraries: `pip install -r requirements.txt` (ensure `requirements.txt` includes `playwright`, `google-generativeai`, `python-dotenv`, `pillow`, potentially `pydantic`).
    *   Install Playwright browsers: `playwright install` (or `playwright install chromium`).
2.  **API Key:** Create a `.env` file in the project root directory and add your Google LLM API key:
    ```
    LLM_API_KEY=YOUR_API_KEY_HERE
    ```
3.  **Running:** Use `main.py` from the command line.
    *   **Record Mode:**
        ```bash
        python main.py --mode record
        ```
        The script will prompt you to enter the test case description. Follow the on-screen instructions to interact with the browser and confirm/override AI suggestions. The recorded test will be saved in the `output/` directory.
    *   **Execute Mode:**
        ```bash
        # Run with visible browser
        python main.py --mode execute --file output/test_your_test_name_timestamp.json

        # Run headlessly
        python main.py --mode execute --file output/test_your_test_name_timestamp.json --headless-execution
        ```
        Replace `output/test_your_test_name_timestamp.json` with the path to your recorded test file. Execution results (summary and detailed JSON) will be printed and saved to `output/`.
4.  **Output:** Recorded tests, execution results, and failure screenshots are saved in the `output/` directory.

# New Updates

### `# Update: llm_client.py (LLMClient)`

*   **Model:** The code initializes and uses `LLM-1.5-flash-latest` rather than `LLM-1.5-flash`.
*   **New Method: `generate_json(Schema_Class, prompt, image_bytes=None)`**
    *   **Purpose:** This new method is crucial for obtaining structured JSON output from the LLM, directly conforming to a predefined Pydantic schema. This replaces the previous pattern of generating text and manually parsing JSON.
    *   **Parameters:**
        *   `Schema_Class`: A Pydantic model class defining the expected JSON structure.
        *   `prompt`: The textual prompt for the LLM.
        *   `image_bytes` (Optional): Image data in bytes for multimodal requests.
    *   **Logic:**
        *   Calls `_wait_for_rate_limit`.
        *   Constructs the request payload, including the prompt and optional image.
        *   Sets the `response_mime_type` to `'application/json'` and provides the `response_schema` based on the `Schema_Class` in the generation configuration.
        *   Handles the response:
            *   If successful, it returns the automatically parsed Pydantic object (`response.parsed`).
            *   Handles content blocking (`response.prompt_feedback`) and other errors.
    *   **Usage:** This method is now used by the `WebAgent` for planning (`_plan_subtasks`), verification (`_get_llm_verification`), AI suggestions (`_determine_action_and_selector_for_recording`), re-planning (`_trigger_re_planning`), and assertion target identification (`_handle_assertion_recording`) to ensure reliable structured data exchange with the LLM.

---

### `# Update: browser_controller.py (BrowserController)`

*   **`get_structured_dom(...)` Logic:**
    *   The documentation previously implied selector generation might happen within `DomService` or `buildDomTree.js`.
    *   The **updated logic** is:
        1.  `get_structured_dom` calls `self._dom_service.get_clickable_elements()` which executes the JS and parses the basic tree, returning a `DOMState` object.
        2.  `get_structured_dom` then **explicitly iterates** through the `selector_map` within the returned `DOMState`.
        3.  For each interactive `DOMElementNode` in the map, it calls `self.get_selector_for_node(node)` (which uses `DomService._enhanced_css_selector_for_element`) to generate the robust CSS selector.
        4.  This generated selector is **assigned to the `node.css_selector` attribute** of the `DOMElementNode` within the `DOMState`.
        5.  Finally, the **populated `DOMState` object** (with nodes containing their pre-generated selectors) is returned.
    *   This ensures that when the `WebAgent` receives the `DOMState`, the interactive elements relevant for suggestions already have their robust selectors readily available.
*   **`wait_for_user_click_or_timeout(timeout_seconds)` Mechanism:**
    *   The method now uses `page.wait_for_function()` which actively polls the browser's JavaScript context.
    *   It specifically waits for the condition `window._recorder_override_selector !== undefined` to become true.
    *   If the condition is met (click occurred), it retrieves the selector value using `page.evaluate("window._recorder_override_selector")`.
    *   The listener removal (`remove_click_listener()`) happens within the `finally` block, ensuring cleanup regardless of whether a click occurred or a timeout happened.
*   **Click Listener JS (`CLICK_LISTENER_JS`) Selector Generation:**
    *   The JavaScript code for the click listener (`CLICK_LISTENER_JS`) implements a **basic** CSS selector generation strategy for user overrides. It prioritizes `id`, `data-testid`, `name`, and falls back to a very simple tag path with `:nth-of-type`. This is less sophisticated than the Python-based `_enhanced_css_selector_for_element` used for AI suggestions/final recording but serves to capture the user's intended target during override.
*   **Highlighting Container ID:**
    *   The Python code in `highlight_element` uses `bw-highlight-container` as the ID for the highlight overlay container. The `buildDomTree.js` file uses `playwright-highlight-container`. This is an inconsistency. *Assuming the Python code (`bw-highlight-container`) is the intended ID for agent-controlled highlights.*

---

### `# Update: agent.py (WebAgent)`

*   **LLM Interaction via `generate_json`:**
    *   All core interactions previously relying on `generate_text` followed by manual JSON parsing (`_clean_llm_response_to_json`) have been **replaced** with calls to `llm_client.generate_json`, providing specific Pydantic schemas for expected outputs. This significantly improves reliability.
    *   **`_plan_subtasks`:** Uses `generate_json` with `PlanSubtasksSchema`.
    *   **`_get_llm_verification`:** Uses `generate_json` with `LLMVerificationSchema`. Supports multimodal input (passing `screenshot_bytes`). Performs post-parse validation (e.g., checks required fields if `verified=True`). Returns the validated result as a dictionary.
    *   **`_determine_action_and_selector_for_recording`:** Uses `generate_json` with `RecorderSuggestionSchema`.
    *   **`_trigger_re_planning`:** Uses `generate_json` with `ReplanSchema`. Supports multimodal input.
    *   **`_handle_assertion_recording`:** Uses `generate_json` with `AssertionTargetIndexSchema` for suggesting the target element index.
    *   The `_clean_llm_response_to_json` method is likely now unused or less critical.
*   **Retrieving Pre-Generated Selectors:**
    *   `_determine_action_and_selector_for_recording` no longer asks the LLM for a selector. It asks for the `index` of the target element. It then uses this index to look up the corresponding `DOMElementNode` in `self._latest_dom_state.selector_map` and retrieves the `node.css_selector` (which was pre-generated by `BrowserController.get_structured_dom`).
*   **New Method: `_handle_llm_verification(planned_step, verification_result)`**
    *   **Purpose:** Handles the workflow after `_get_llm_verification` returns a result. It bridges the gap between the AI's verification and user confirmation/action.
    *   **Logic:**
        *   Prints the AI's verification result (Passed/Failed) and reasoning.
        *   **If AI Verified (`verified=True`):**
            *   Retrieves the target `element_index`, suggested `assertion_type`, and `parameters` from the result.
            *   Looks up the element node and its selector using the `element_index`.
            *   Highlights the target element (`BrowserController.highlight_element`).
            *   Prints the AI's suggested assertion details (type, selector, params).
            *   Prompts the user: Accept (Y/Enter), Define Manually (M), Skip (S), Abort (A).
            *   If accepted: Records the assertion step using the AI's suggested type, parameters, and the resolved selector. Handles `assert_element_count` needing a manual selector input if the AI provided index 0. Updates `TaskManager`.
            *   If manual: Calls `_handle_assertion_recording`.
            *   If skip/abort: Updates `TaskManager` / sets abort flag.
        *   **If AI Failed Verification (`verified=False`):**
            *   Prints the AI's reasoning.
            *   Checks reasoning for keywords suggesting potential *alternative* success states (e.g., "successfully logged in", "congratulations") and notes this possibility to the user.
            *   Prompts the user: Define Manually (M), Skip (S), Abort (A).
            *   Handles user choice, falling back to `_handle_assertion_recording` if 'M' is chosen.
*   **`_handle_interactive_step_recording(...)` Updates:**
    *   **Execution Timing:** Clarified that browser action execution (`_execute_action_for_recording`) happens *after* the user chooses to accept the AI suggestion or provides an override selector.
    *   **Parameterization Prompt:** After successfully executing and recording a `type` action (whether via AI suggestion or override), it now explicitly prompts the user: `Parameterize value '{text}'? Enter name or leave blank:`. If a name is provided, it's added to the recorded step's `parameters` as `parameter_name`.
    *   **Execution Failure Handling:** If `_execute_action_for_recording` fails (either for the AI suggestion or the user override), the user is prompted: Retry suggestion (R - marks task as failed for retry), Skip (S), or Abort (A).
*   **Re-planning Triggers in `record()` Loop:**
    *   The main `record` loop now explicitly checks for two conditions to trigger `_trigger_re_planning`:
        1.  **Repeated Suggestion Failures:** If `_determine_action_and_selector_for_recording` fails (`suggestion_failed`) more times than `max_retries_per_subtask` for the *same* step index (tracked by `_consecutive_suggestion_failures` and `_last_failed_step_index`).
        2.  **Action Execution Failures:** If `_handle_interactive_step_recording` results in the task being marked as `failed` due to an error during the actual browser action execution (e.g., `_execute_action_for_recording` returned `success=False`).
    *   If re-planning succeeds and inserts steps, the loop continues; otherwise, the original step is marked as failed/skipped based on user choice or re-planning failure.

---

### `# Update: dom/buildDomTree.js (Browser-side Script)`

*   **Interactivity Checks (`isInteractiveElement`):** The logic for determining if an element is interactive is more sophisticated than just checking tags/roles. It now includes:
    *   Checking `cursor` style (`pointer` suggests interactive, `not-allowed`/`default`/etc. suggests non-interactive).
    *   Checking standard `disabled`, `readonly`, `inert` attributes/properties.
    *   Checking specific `contenteditable` status for rich text editors.
    *   Checking common interactive tag names (`a`, `button`, `input`, `select`, `textarea`, `details`, `summary`, `label`, `option`, etc.).
    *   Checking common interactive ARIA roles (`button`, `link`, `menuitem`, `checkbox`, `radio`, `tab`, etc.).
    *   Checking for specific classes or attributes often used for dropdowns/toggles (`dropdown-toggle`, `data-toggle`, `aria-haspopup`).
    *   *Removed/Deprioritized:* Direct checking for JS event handlers (`onclick`, `getEventListeners`) due to unreliability/complexity.
*   **Caching (`DOM_CACHE`):** Implements `WeakMap` based caching for `getBoundingClientRect` and `getComputedStyle` results within a single run of the script to reduce redundant DOM queries and improve performance. Cache hits/misses are tracked in debug mode.
*   **Performance Metrics (`PERF_METRICS`):** If `debugMode` is enabled, the script collects detailed performance timings for various internal functions (`isInteractiveElement`, `isElementVisible`, `isTopElement`, etc.) and DOM operations (`getBoundingClientRect`, `getComputedStyle`), along with cache statistics and node processing counts.
*   **Special Handling:** Includes explicit logic to traverse into `<iframe>` content and `shadowRoot` elements. It also processes children of `contenteditable` elements or known rich text editor patterns (like TinyMCE) to capture their structure/text.
*   **Highlighting Container ID:** Uses `playwright-highlight-container` as the ID for the highlight overlay container. *This conflicts with the ID used in the Python `BrowserController.highlight_element`.*

---

### `# Update: dom/views.py (Python Data Structures)`

*   **`DOMElementNode`:**
    *   Added the field `css_selector: Optional[str] = None`. This field is populated *after* parsing by the `BrowserController.get_structured_dom` method using the robust selector generation logic.
*   **`DOMElementNode.generate_llm_context_string(...)`:**
    *   Now accepts a `context_purpose: Literal['action', 'verification']` parameter (defaulting to `'action'`).
    *   The number of static (non-interactive) elements included is limited based on this purpose (`max_static_elements_action` vs. `max_static_elements_verification`). Verification mode allows more static elements.
    *   The criteria for *which* static elements are included also differ:
        *   `verification` mode includes common text tags (`p`, `h*`, `span`, `div`, `li`, etc.) or any static element with direct text content or attributes.
        *   `action` mode is stricter, potentially only including specific static tags like `h*`, `label` if they have text/attributes, or `div`s with IDs.
    *   Static elements included in the output string are explicitly marked with ` (Static)` for clarity in the LLM prompt.

---

### `# Update: dom/service.py (DomService)`

*   **`_enhanced_css_selector_for_element(element)` Usage:** This static method provides the robust selector generation logic. It is now called by `BrowserController.get_structured_dom` *after* the DOM tree is constructed by `_construct_dom_tree`, iterating through the `selector_map` to populate the `css_selector` attribute on each interactive `DOMElementNode`.

---

### `# Update: main.py (Executor Mode)`

*   **Execution Results Saving:** In `execute` mode, after `executor.run_test` completes, `main.py` now saves the **full** returned result dictionary (which includes status, duration, step details, failure info, screenshots, and potentially *all captured console messages*) to a timestamped JSON file in the `output/` directory (e.g., `execution_result_test_your_test_name_timestamp.json`).

---

### `# Update: Key Data Schemas`</h3>

*   **New Pydantic Schemas (Used with `generate_json` in `agent.py`):**
    *   **`PlanSubtasksSchema`:**
        *   Purpose: Defines the structure for the initial test plan generated by the LLM.
        *   Fields: `planned_steps: List[str]` (A list of natural language step descriptions).
    *   **`LLMVerificationSchema`:**
        *   Purpose: Defines the structure for the LLM's response during a verification step.
        *   Fields:
            *   `verified: bool` (Required: True if condition met, False otherwise).
            *   `assertion_type: Optional[Literal['assert_text_equals', ...]]` (Required if verified=True: The suggested assertion type reflecting the *actual* observed state).
            *   `element_index: Optional[int]` (Required if verified=True: Index of the confirming element from context).
            *   `parameters: Optional[LLMVerificationParamsSchema]` (Required if verified=True and assertion needs params: Parameters reflecting the *actual* observed state).
            *   `reasoning: str` (Required: Explanation for the result).
    *   **`LLMVerificationParamsSchema`:**
        *   Purpose: Defines parameters within a successful verification result.
        *   Fields: `expected_text`, `attribute_name`, `expected_value`, `expected_count` (all optional, depending on `assertion_type`).
    *   **`ReplanSchema`:**
        *   Purpose: Defines the structure for the LLM's response when suggesting recovery steps or aborting.
        *   Fields:
            *   `recovery_steps: Optional[List[str]]` (1-3 recovery step descriptions if possible).
            *   `action: Optional[Literal["abort"]]` (Set to 'abort' if recovery not possible).
            *   `reasoning: Optional[str]` (Explanation, especially if aborting).
    *   **`RecorderSuggestionSchema`:**
        *   Purpose: Defines the structure for the LLM's suggestion for a `click` or `type` action during recording.
        *   Fields:
            *   `action: Literal["click", "type", "action_not_applicable", "suggestion_failed"]` (Required: Suggested action or status).
            *   `parameters: RecorderSuggestionParamsSchema` (Parameters for the action).
            *   `reasoning: str` (Required: Explanation).
    *   **`RecorderSuggestionParamsSchema`:**
        *   Purpose: Defines parameters for a recorder action suggestion.
        *   Fields: `index: Optional[int]` (Required for click/type: Target element index), `text: Optional[str]` (Required for type: Text to type).
    *   **`AssertionTargetIndexSchema`:**
        *   Purpose: Defines the structure for the LLM's suggestion of a target element index during manual assertion definition.
        *   Fields: `index: Optional[int]` (Index or null), `reasoning: Optional[str]` (Explanation if null).

---